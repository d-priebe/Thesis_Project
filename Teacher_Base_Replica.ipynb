{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J3Q-vhzaZTJ",
        "outputId": "48eb7083-0e64-4203-a81e-50af74af9f96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import librosa\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3N0tRhGoaafI"
      },
      "outputs": [],
      "source": [
        "# Change working directory to folder location\n",
        "os.chdir('/content/drive/MyDrive/Thesis_Material')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHCHbdujazj-"
      },
      "outputs": [],
      "source": [
        "#Teacher Architecture: Code from Cretois et al. (2022)\n",
        "class VGG11(nn.Module):\n",
        "    def __init__(self, T=5.0):\n",
        "        super().__init__()\n",
        "        self.T = T\n",
        "\n",
        "        # First set of conv layers -> depth of 64\n",
        "        self.conv11 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
        "        self.bn11  = nn.BatchNorm2d(64)\n",
        "        \n",
        "        # Second set of conv layers -> from depth 64 to depth 128\n",
        "        self.conv21 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn21  = nn.BatchNorm2d(128)\n",
        "        \n",
        "        # Third set of conv layers -> from depth 128 to depth 256\n",
        "        self.conv31 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn31  = nn.BatchNorm2d(256)\n",
        "        self.conv32 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.bn32  = nn.BatchNorm2d(256)\n",
        "                      \n",
        "        # Fourth set of conv layers -> from depth 128 to depth 256\n",
        "        self.conv41 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.bn41  = nn.BatchNorm2d(512)\n",
        "        self.conv42 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn42  = nn.BatchNorm2d(512)\n",
        "        \n",
        "        # Fifth set of conv layers -> from depth 128 to depth 256\n",
        "        self.conv51 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn51  = nn.BatchNorm2d(512)\n",
        "        self.conv52 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn52  = nn.BatchNorm2d(512)\n",
        "              \n",
        "        # First FC layer\n",
        "        self.fc1 = nn.Linear(4 * 4 * 512,  4096)\n",
        "        # Second FC layer\n",
        "        self.fc2 = nn.Linear( 4096,  4096)\n",
        "        \n",
        "        # Add a dropout layer\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        \n",
        "        # Output\n",
        "        self.fc3 = nn.Linear(4096, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "     \n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # MaxPool for the first block --> img from 128x128 to 64x64\n",
        "        out = F.max_pool2d(torch.relu(self.bn11(self.conv11(x))), 2)\n",
        "\n",
        "        # MaxPool for the first block --> img from 64x64 to 32x32\n",
        "        out = F.max_pool2d(torch.relu(self.bn21(self.conv21(out))), 2)\n",
        "\n",
        "        # MaxPool for the first block --> img from 32x32 to 16x16\n",
        "        out = torch.relu(self.bn31(self.conv31(out)))\n",
        "        out = F.max_pool2d(torch.relu(self.bn32(self.conv32(out))), 2)\n",
        "        \n",
        "        # MaxPool for the first block --> img from 16x16 to 8x8\n",
        "        out = torch.relu(self.bn41(self.conv41(out)))\n",
        "        out = F.max_pool2d(torch.relu(self.bn42(self.conv42(out))), 2)\n",
        "        \n",
        "        # MaxPool for the first block --> img from 8x8 to 4x4\n",
        "        out = torch.relu(self.bn51(self.conv51(out)))\n",
        "        out = F.max_pool2d(torch.relu(self.bn52(self.conv52(out))), 2)\n",
        "        \n",
        "        # Flatten the whole thing: image of 4 x 4 * 512 \n",
        "        out = out.view(-1, 4 * 4 * 512)\n",
        "        out = self.dropout(torch.relu(self.fc1(out)))\n",
        "        out = self.dropout(torch.relu(self.fc2(out)))\n",
        "\n",
        "        out = self.sigmoid(self.fc3(out))\n",
        "       \n",
        "        return(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zt1-MeHazmJ"
      },
      "outputs": [],
      "source": [
        "#Generate Mel-Spec\n",
        "def generate_mel_spectrogram(x, sr, show=False, resize=True):\n",
        "    sgram = librosa.stft(x, n_fft=1024, hop_length=376)\n",
        "    sgram_mag, _ = librosa.magphase(sgram)\n",
        "    mel_scale_sgram = librosa.feature.melspectrogram(S=sgram_mag, sr=sr, n_mels=128)\n",
        "    mel_sgram = librosa.amplitude_to_db(mel_scale_sgram)\n",
        "    if resize:\n",
        "        # Crop the mel spectrogram to 128x128\n",
        "        mel_sgram = mel_sgram[:, :128]\n",
        "    if show:\n",
        "        librosa.display.specshow(mel_sgram, sr=sr, x_axis='time', y_axis='mel')\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "    return mel_sgram\n",
        "\n",
        "#Dataset\n",
        "class SpeechDataset(Dataset):\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data[idx]\n",
        "        y = self.labels[idx]\n",
        "        \n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        x = torch.tensor(x)\n",
        "        return x, torch.tensor(y).unsqueeze(-1)\n",
        "        \n",
        "    \n",
        "  \n",
        "# Load data\n",
        "def load_data(data_path):\n",
        "    speech_dir = os.path.join(data_path, 'speech')\n",
        "    no_speech_dir = os.path.join(data_path, 'no_speech')\n",
        "\n",
        "    speech_files = [os.path.join(speech_dir, f) for f in os.listdir(speech_dir) if f.endswith('.wav')]\n",
        "    no_speech_files = [os.path.join(no_speech_dir, f) for f in os.listdir(no_speech_dir) if f.endswith('.wav')]\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for file in speech_files + no_speech_files:\n",
        "        x, sr = librosa.load(file)\n",
        "        mel_sgram = generate_mel_spectrogram(x, sr)\n",
        "        data.append(mel_sgram)\n",
        "    \n",
        "    labels = [1] * len(speech_files) + [0] * len(no_speech_files)\n",
        "\n",
        "    return data, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbGFtb5uazoy"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load teacher model and weights\n",
        "teacher = VGG11()\n",
        "\n",
        "Train_Data ='/content/drive/MyDrive/Thesis_Material/Synthetic_Dataset'\n",
        "# Load  data\n",
        "data, labels = load_data(Train_Data) \n",
        "\n",
        "# Split data into train, val, and test sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.25, random_state=42)\n",
        "\n",
        "# SpeechDataset instances of training, validation, testing\n",
        "train_dataset = SpeechDataset(train_data, train_labels, transform=ToTensor())\n",
        "val_dataset = SpeechDataset(val_data, val_labels, transform=ToTensor())\n",
        "test_dataset = SpeechDataset(test_data, test_labels, transform=ToTensor()) \n",
        "\n",
        "# DataLoaders for training, validation, testing\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2l_StQxbQEu",
        "outputId": "b8e924ab-42ab-40a5-9916-ed77e415ca56"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-538a1b9130b6>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Train Loss: 11.1267, Val Loss: 24.7683, Val AUC: 0.5553, Val F1: 0.6624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-538a1b9130b6>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Train Loss: 5.5901, Val Loss: 10.4496, Val AUC: 0.6381, Val F1: 0.5577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-538a1b9130b6>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Train Loss: 3.0244, Val Loss: 18.1219, Val AUC: 0.8130, Val F1: 0.7984\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-538a1b9130b6>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Train Loss: 0.7759, Val Loss: 1.1855, Val AUC: 0.9797, Val F1: 0.9340\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-538a1b9130b6>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Train Loss: 0.5406, Val Loss: 0.6426, Val AUC: 0.9619, Val F1: 0.8938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-538a1b9130b6>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Train Loss: 0.8545, Val Loss: 0.3618, Val AUC: 0.9860, Val F1: 0.9653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-538a1b9130b6>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Train Loss: 0.4065, Val Loss: 0.3690, Val AUC: 0.9861, Val F1: 0.9703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-538a1b9130b6>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Train Loss: 0.3661, Val Loss: 0.6661, Val AUC: 0.9795, Val F1: 0.9444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-538a1b9130b6>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Train Loss: 0.5866, Val Loss: 0.8128, Val AUC: 0.9504, Val F1: 0.8741\n",
            "Early stopping after 9 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-538a1b9130b6>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.6505, Test AUC: 0.9453, Test F1: 0.8739\n"
          ]
        }
      ],
      "source": [
        "#Training instantiation:\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Set hyperparameters\n",
        "num_epochs = 50\n",
        "T = 5.0\n",
        "\n",
        "torch.manual_seed(18)\n",
        "model = VGG11().to(device)\n",
        "\n",
        "# loss function & optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=.001)\n",
        "\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "  \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "       \n",
        "        loss = criterion(outputs, targets.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    return running_loss / len(dataloader)\n",
        "\n",
        "def evaluate_model(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_outputs = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "        \n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets.float())\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            all_outputs.append(outputs.detach().cpu().numpy())\n",
        "            all_targets.append(targets.detach().cpu().numpy())\n",
        "\n",
        "    all_outputs = np.concatenate(all_outputs)\n",
        "    all_targets = np.concatenate(all_targets)\n",
        "\n",
        "    auc = roc_auc_score(all_targets, all_outputs)\n",
        "    f1 = f1_score(all_targets, np.round(all_outputs))\n",
        "\n",
        "    return running_loss / len(dataloader), auc, f1\n",
        "\n",
        "# Train and evaluate model\n",
        "patience = 3\n",
        "no_improvement_count = 0\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_auc, val_f1 = evaluate_model(model, val_loader, criterion, device)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}, Val F1: {val_f1:.4f}')\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        no_improvement_count = 0\n",
        "    else:\n",
        "        no_improvement_count += 1\n",
        "        if no_improvement_count >= patience:\n",
        "            print(f'Early stopping after {epoch + 1} epochs')\n",
        "            break\n",
        "\n",
        "# Test model\n",
        "test_loss, test_auc, test_f1 = evaluate_model(model, test_loader, criterion, device)\n",
        "print(f'Test Loss: {test_loss:.4f}, Test AUC: {test_auc:.4f}, Test F1: {test_f1:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdVif-3GbQan",
        "outputId": "d0f4e296-cf7c-4f01-b850-eb129f757845"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-538a1b9130b6>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.6505, Test AUC: 0.9453, Test F1: 0.8739\n"
          ]
        }
      ],
      "source": [
        "#model evaulation \n",
        "# Test model\n",
        "test_loss, test_auc, test_f1 = evaluate_model(model, test_loader, criterion, device)\n",
        "print(f'Test Loss: {test_loss:.4f}, Test AUC: {test_auc:.4f}, Test F1: {test_f1:.4f}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
